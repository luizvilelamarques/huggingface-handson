{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cdf6dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bf85ea0f1c145ca8e360a9c75bae5b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lamarques\\Desktop\\hugginface\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\lamarques\\.cache\\huggingface\\hub\\models--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "992d803bfb2142879ff04ad8003b5fc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56162132c735401c9b70a21c30742a7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ec5665dabfc4798bf9e48e0caa7db8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d9dc1865d46494fb3e0ec88b6fb4884",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2650b35555a343469054e9ea52d889dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d77bc615e224efca21438ef5b92cdc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Texto Gerado ---\n",
      "Certo dia, em uma floresta mágica, um dragão solitário acordou de seu sono de mil anos.\n",
      "\n",
      "The following is the audio of the meeting between the President and the Commission President (Síbal de Segura) on the issue of the use of the military force against the armed forces of the Venezuelan Government and the authorities of their constituent republics.\n",
      "\n",
      "Síbal de Segura, President of Venezuela\n",
      "\n",
      "\"There is no justification for military action, no justification for any other measures or tactics, and the Venezuelan Government will make no exceptions whatsoever to this demand.\"\n",
      "\n",
      "Síbal de Segura, President of Venezuela\n",
      "\n",
      "\"The President's proposal is for the use of the military force against the Armed Forces of the Venezuelan Government and the authorities of their constituent republics, and not for the use of military force against other citizens of the constituent republics, if they are not prepared to act in accordance with the constitutional authority of the Venezuelan Government.\"\n",
      "\n",
      "Síbal de Segura, President of Venezuela\n",
      "\n",
      "\"The Venezuelan government will not be able to use the military force against the Armed Forces of the Venezuelan Government and the authorities of their constituent republics.\"\n",
      "\n",
      "Síbal de Segura, President of Venezuela\n",
      "\n",
      "SAS, MOSCOW\n",
      "\n",
      "\"The Venezuelan Government has taken the initiative to use all the measures\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Carrega o pipeline de geração de texto com o modelo pierreguillou/gpt2-small-portuguese\n",
    "gerador = pipeline(\"text-generation\", model=\"pierreguillou/gpt2-small-portuguese\")\n",
    "\n",
    "# Seu prompt (a frase inicial)\n",
    "prompt = \"Certo dia, em uma floresta mágica, um dragão solitário acordou de seu sono de mil anos.\"\n",
    "\n",
    "# Gera o texto\n",
    "# max_length define o número máximo de tokens (palavras/caracteres)\n",
    "# num_return_sequences define quantas sequências (opções de texto) o modelo deve gerar\n",
    "resultados = gerador(prompt, max_length=150, num_return_sequences=1)\n",
    "\n",
    "# Imprime o resultado\n",
    "for resultado in resultados:\n",
    "    print(\"--- Texto Gerado ---\")\n",
    "    print(resultado['generated_text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
